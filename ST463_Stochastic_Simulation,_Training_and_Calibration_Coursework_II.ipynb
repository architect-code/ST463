{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/architect-code/ST463/blob/main/ST463_Stochastic_Simulation%2C_Training_and_Calibration_Coursework_II.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ST463 - Stochastic Simulation, Training and Calibration: Coursework II\n",
        "\n",
        "Some general remarks about the exercises:\n",
        "*   If useful, feel free to reuse functions from the lecture without copying them to the exercise solution box; namely, copy them under the text **Code from the lectures** below.\n",
        "*   You **must** make your code readable by humans (and not just by the Python interpreter): choose informative function and variable names and use consistent formatting. Feel free to check the [PEP 8 Style Guide for Python](https://www.python.org/dev/peps/pep-0008/) for the widely adopted coding conventions or [this guide for explanation](https://realpython.com/python-pep8/).\n",
        "*   In addition to the previous point, you **must** write a paragraph before each function that explaines what the function will do. Just add a `Text` type cell.      \n",
        "*   If it is more convenient for you, you can submit in a `.pdf` file your comments and theorethical answers; **Important**: name the file as `ST463 - Coursework II - your candidate number.pdf` (see also below). In any case, you **must** submit a `.pdf` file named as before where you copy your Google Colab link; **Important**: make sure that when you share the link you select the option `Anyone with the link` and the role of `Editor`; you can also use a local Python file, if you prefer. **Important**: Submit also a `.pdf` with a printed copy of your work: you can do this by selecting `File > Print` in the jupyter menu.\n",
        "*   Make sure that the full notebook runs without errors before submitting your work. This you can do by selecting `Kernel > Restart & Run All` in the jupyter menu. **Important**: this is not a programming course, so the important thing is that the code is correct."
      ],
      "metadata": {
        "id": "Xqg_C1JhxDDA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please enter your **candidate number** (11 is just an example). **Important**: Marking will be conducted **anonymously**; please do not include your name on any part of the report. Read also the **Course Information** on Moodle."
      ],
      "metadata": {
        "id": "XBCiWx0D7Qfq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lh3_UOCPuReN"
      },
      "outputs": [],
      "source": [
        "CANDIDATE_NUMBERS = 11"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Code from the lectures**:"
      ],
      "metadata": {
        "id": "l3xKaapi_FiN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy here any code from the lectures."
      ],
      "metadata": {
        "id": "QEH_2j7rQh_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 1: Generalized Linear Models [40]\n",
        "\n",
        "A Generalized Linear Model has the following form:\n",
        "\\begin{equation*}\n",
        "    p(y|\\mathbf{x}, \\mathbf{w}, \\tau)=h(y,\\tau)\\exp\\left\\{\\frac{y \\eta - A(\\eta)}{d(\\tau)}\\right\\},\n",
        "\\end{equation*}\n",
        "\n",
        "where $p$ is the probability mass function or probability density function of $y$, $\\eta := \\mathbf{w}^{T}\\mathbf{x}$ is the natural parameter, $A(\\eta)$ is the log normalizer, and $\\tau$ is the dispersion parameter, which is typically related to the variance of the conditional distribution. $h(y,\\tau)$ is a normalization factor such that $p(y|\\mathbf{x}, \\mathbf{w}, \\tau)$ sums/integrates to 1 over $y$.  We denote the mapping from the linear input $\\eta = \\mathbf{w}^{T}\\mathbf{x}$ to the conditional expectation of $y$ as $\\mu=\\ell^{-1}(\\eta)$ where $\\ell$ is known as the link function, and $\\ell^{âˆ’1}$\n",
        "is known as the mean function.\n",
        "\n",
        "\n",
        "1.   Show that linear regression and logistic regression are special cases of the GLM in the above equation. **[10 Marks]**\n",
        "2.    Consider the Poisson regression model, which is defined by the following probability mass function\n",
        "\\begin{equation*}\n",
        "    p(y|\\mathbf{x}, \\mathbf{w})=\\text{Pois}(y|\\exp(\\mathbf{w}^{T} \\mathbf{x})).\n",
        "\\end{equation*}\n",
        "Show that Poisson regression belongs to the family of GLMs defined in the above equation. **[10 Marks]**\n",
        "3. Consider a dataset $\\{(\\mathbf{x}_n, \\mathbf{y}_n)\\}_{n=1}^{N}$, where $\\mathbf{x}_n \\in \\mathbb{R}^d$ and $y_n$ is the response variable. Derive the negative log-likelihood (NLL) for the GLM on this dataset based on the above equation. Explain how the derived NLL is equivalent to the square loss (for linear regression) and binary cross entropy loss (for logistic regression) for finding the optimal $\\mathbf{w}$.**[10 Marks]**\n",
        "4. Derive the negative log-likelihood (NLL) loss function for the Poisson regression model using the results from sub-questions 2 and 3. Simplify the expression as much as possible.**[10 Marks]**"
      ],
      "metadata": {
        "id": "8ofUHBn1haZl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 2: German Credit Classification [55 Marks].\n",
        "\n",
        "In this exercise, you will use th `german.csv` dataset uploaded on the **Moodle** page of our course. The dataset was used as part of the Statlog project, a European-based initiative in the 1990s to evaluate and compare a large number (at the time) of machine learning algorithms on a range of different classification tasks. Below you can find a function that you can use to upload the dataset.\n",
        "\n",
        "> Add blockquote\n",
        "\n",
        "\n",
        "\n",
        "The German credit dataset describes financial and banking details for customers. The task is to determine whether the customer is good or bad. The assumption is that the task involves predicting whether a customer will pay back a loan or credit. The dataset includes 1,000 examples and 20 input variables, 7 of which are numerical (integer) and 13 are categorical:\n",
        "\n",
        "\n",
        "\n",
        "1.   Status of existing checking account.\n",
        "2.   Duration in month.\n",
        "3.   Credit history.\n",
        "4.   Purpose.\n",
        "5.   Credit amount.\n",
        "6.   Savings account.\n",
        "7.   Present employment since.\n",
        "8.   Installment rate in percentage of disposable income.\n",
        "9.   Personal status and sex.\n",
        "10.  Other debtors.\n",
        "11.  Present residence since.\n",
        "12.  Property.\n",
        "13.  Age in years.\n",
        "14.  Other installment plans.\n",
        "15.  Housing.\n",
        "16.  Number of existing credits at this bank.\n",
        "17.  Job.\n",
        "18.  Number of dependents.\n",
        "19.  Telephone.\n",
        "20.  Foreign worker.\n",
        "\n",
        "Some of the categorical variables have an ordinal relationship, such as *Savings account*, although most do not. There are two outcome classes, $1$ for good customers and $2$ for bad customers. Good customers are the default or negative class, whereas bad customers are the exception or positive class.\n",
        "\n",
        "A cost matrix is provided with the dataset that gives a different penalty to each misclassification error for the positive class. Specifically, a cost of five is applied to a false negative (marking a bad customer as good) and a cost of one is assigned for a false positive (marking a\n",
        "good customer as bad). This suggests that the positive class is the focus of the prediction task and that it is more costly to the bank or financial institution to give money to a bad customer than to not give money to a good customer.\n",
        "\n",
        "1.   Compute, in `Python`, the so-called **ratio** for this dataset and create one histogram for each of the seven numeric input variables and one class label in the dataset. Comment on the latter histograms (e.g., What is the underline distribution?) **[5 Marks]**  \n",
        "2.   Compute, in `Python`, the baseline performance for the initial German dataset by using repeated stratified $k$-fold cross-validation. Comment on the results. **[10 Marks]**\n",
        "3.   Evaluate, in `Python`, the following machine learning models on the initial German credit dataset:\n",
        "    *   Logistic Regression (LR).\n",
        "    *   Naive Bayes (NB).\n",
        "    *   Support Vector Machine (SVM).  \n",
        "Comment on the results. **[15 Marks]**\n",
        "\n",
        "4.  Apply, in `Python`, the oversampling technique SMOTE on the initial German dataset and evaluate the machine learning models in `3.` on the new dataset. Comment on the results. **[15 Marks]**\n",
        "5.  Make prediction on new data and comments on the results.**[10 Marks]**\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZqgS55hdvh-D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#def load_dataset(full_path):\n",
        "## load the dataset as a numpy array\n",
        "#\tdataframe = read_csv(full_path, header=None)\n",
        "## split into inputs and outputs\n",
        "#\tlast_ix = len(dataframe.columns) - 1\n",
        "#\tX, y = dataframe.drop(last_ix, axis=1), dataframe[last_ix]\n",
        "## select categorical features\n",
        "#\tcat_ix = X.select_dtypes(include=['object', 'bool']).columns\n",
        "## one hot encode cat features only\n",
        "#\tct = ColumnTransformer([('o',OneHotEncoder(),cat_ix)], remainder='passthrough')\n",
        "#\tX = ct.fit_transform(X)\n",
        "## label encode the target variable to have the classes 0 and 1\n",
        "#\ty = LabelEncoder().fit_transform(y)\n",
        "#\treturn X, y"
      ],
      "metadata": {
        "id": "rJ8cvJh6mUGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comments on Coursework III [5 Marks]\n",
        "\n",
        "This section should contain a critical thought to the process and lessons learned from the Coursework III.\n",
        "\n",
        "1.   CANDIDATE NUMBER:"
      ],
      "metadata": {
        "id": "pCIyVN8wtX5C"
      }
    }
  ]
}